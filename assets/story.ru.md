# ğŸ¤– Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ñ‹Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼

ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ĞµĞ»Ğ¸!

## Ğ•ÑĞ»Ğ¸ Ğ²ĞºÑ€Ğ°Ñ‚Ñ†Ğµ

Ğ¯ ÑĞ¾Ğ·Ğ´Ğ°Ğ» Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ [**ğŸ¤– Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ Ğ¼Ñ‹ÑˆĞ¸Ğ½Ğ½Ñ‹Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼**](https://github.com/trekhleb/machine-learning-experiments) Ğ½Ğ° GitHub. ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚ ÑĞ¾ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¸Ğ· ğŸ‹ï¸ _Jupyter/Colab Ğ½Ğ¾ÑƒÑ‚Ğ±ÑƒĞºĞ°_, Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‰ĞµĞ³Ğ¾ ĞºĞ°Ğº Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ»Ğ°ÑÑŒ, Ğ¸ ğŸ¨ _Ğ”ĞµĞ¼Ğ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞºĞ¸_, Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑ‰ĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¸ Ğ¿Ñ€ÑĞ¼Ğ¾ Ğ² Ğ²Ğ°ÑˆĞµĞ¼ Ğ±Ñ€Ğ°ÑƒĞ·ĞµÑ€Ğµ. 

ĞĞµÑĞ¼Ğ¾Ñ‚Ñ€Ñ Ğ½Ğ° Ñ‚Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ "Ñ‚ÑƒĞ¿Ğ¾Ğ²Ğ°Ñ‚ĞµĞ½ÑŒĞºĞ¸Ğ¼Ğ¸" (Ğ¿Ğ¾Ğ¼Ğ½Ğ¸Ñ‚Ğµ, ÑÑ‚Ğ¾ Ğ²ÑĞµĞ³Ğ¾-Ğ»Ğ¸ÑˆÑŒ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹, Ğ° Ğ½Ğµ Ğ²Ñ‹Ğ»ĞµĞ·Ğ°Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ´, Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğº Ğ·Ğ°Ğ»Ğ¸Ğ²ĞºĞµ Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ´Ğ°ĞºÑˆĞ½ Ğ¸ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞµĞ¼Ñƒ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ½Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Tesla), Ğ¾Ğ½Ğ¸ Ğ±ÑƒĞ´ÑƒÑ‚ ÑÑ‚Ğ°Ñ€Ğ°Ñ‚ÑŒÑÑ ĞºĞ°Ğº Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ñ‡Ñ‚Ğ¾Ğ±Ñ‹:

- ğŸ–Œ Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ñ‚ÑŒ Ñ†Ğ¸Ñ„Ñ€Ñ‹ Ğ¸ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ğµ ÑĞºÑĞºĞ¸Ğ·Ñ‹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ²Ñ‹ Ğ½Ğ°Ñ€Ğ¸ÑÑƒĞµÑ‚Ğµ Ğ² Ğ±Ñ€Ğ°ÑƒĞ·ĞµÑ€Ğµ
- ğŸ“¸ ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ğ¸ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ñ‚ÑŒ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹ Ğ½Ğ° Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸Ğ· Ğ²Ğ°ÑˆĞµĞ¹ ĞºĞ°Ğ¼ĞµÑ€Ñ‹
- ğŸŒ… ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ, Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ²Ğ°Ğ¼Ğ¸
- ğŸ“ ĞĞ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ñ Ğ²Ğ°Ğ¼Ğ¸ Ğ¿Ğ¾ÑĞ¼Ñƒ Ğ² ÑÑ‚Ğ¸Ğ»Ğµ Ğ¨ĞµĞºÑĞ¿Ğ¸Ñ€Ğ°
- âœŠğŸ–âœŒï¸ Ğ˜ Ğ´Ğ°Ğ¶Ğµ Ğ¿Ğ¾Ğ¸Ğ³Ñ€Ğ°Ñ‚ÑŒ Ñ Ğ²Ğ°Ğ¼Ğ¸ Ğ² ĞºĞ°Ğ¼ĞµĞ½ÑŒ-Ğ½Ğ¾Ğ¶Ğ½Ğ¸Ñ†Ñ‹-Ğ±ÑƒĞ¼Ğ°Ğ³Ğ°
- Ğ¸ Ğ¿Ñ€. 

Ğ¯ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ» Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° _Python_ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ _TensorFlow 2_ Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ _Keras_. Ğ”Ğ»Ñ Ğ´ĞµĞ¼Ğ¾-Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ» _React_ Ğ¸ _JavaScript_ Ğ²ĞµÑ€ÑĞ¸Ñ _Tensorflow_. 

![Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ñ‹Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/repository-cover.png)

## ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹

âš ï¸ Ğ”Ğ»Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ°, Ğ´Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ğ¼ÑÑ Ñ Ğ½Ğ°ÑˆĞ¸Ğ¼Ğ¸ Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸.ï¸ Ğ ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ **ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ñ‹** Ñ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ñ‹Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½ĞµĞ¼, Ğ° **Ğ½Ğµ** Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğµ Ğº "Ğ·Ğ°Ğ»Ğ¸Ğ²ĞºĞµ Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ´Ğ°ĞºÑˆĞ½", Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸ Ñ‚Ğ¾Ğ½ĞºĞ¾ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸. Ğ­Ñ‚Ğ¾Ñ‚ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ ÑĞºĞ¾Ñ€ĞµĞµ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶ Ğ½Ğ° Ğ¿ĞµÑĞ¾Ñ‡Ğ½Ğ¸Ñ†Ñƒ, Ğ² ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ¸ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°Ğ¼Ğ¸ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ¸Ğ¼ĞµÑ‚ÑŒ 60% Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ñ…, Ğ¿ÑƒÑĞºĞ°Ğ¹, 97%), Ğ° Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿ĞµÑ€ĞµÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¸ Ğ½ĞµĞ´Ğ¾ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ (overfitting vs underfitting).

ĞŸĞ¾ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ¸Ğ½Ğ¾Ğ³Ğ´Ğ° Ğ²Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ ÑƒĞ²Ğ¸Ğ´ĞµÑ‚ÑŒ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ Ğ²Ñ€Ğ¾Ğ´Ğµ:

![Ğ¢ÑƒĞ¿ĞµĞ½ÑŒĞºĞ°Ñ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/story/01-dumb-model.png)

ĞĞ¾ Ğ±ÑƒĞ´ÑŒÑ‚Ğµ Ñ‚ĞµÑ€Ğ¿ĞµĞ»Ğ¸Ğ²Ñ‹, Ğ¸Ğ½Ğ¾Ğ³Ğ´Ğ° ÑÑ‚Ğ° Ğ¶Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ²Ñ‹Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ Ğ±Ğ¾Ğ»ĞµĞµ "ÑƒĞ¼Ğ½Ğ¾Ğµ" ğŸ¤“:

![Ğ‘Ğ¾Ğ»ĞµĞµ ÑƒĞ¼Ğ½Ğ°Ñ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/story/02-smart-model.png)

## ĞŸÑ€ĞµĞ´Ñ‹ÑÑ‚Ğ¾Ñ€Ğ¸Ñ

I'm a [software engineer](https://www.linkedin.com/in/trekhleb/) and for the last several years now I've been doing mostly frontend and backend programming. In my spare time, as a hobby, I decided to dig into machine learning topics to make it less _like magic_ and _more like math_ to myself.

1. ğŸ—“ Since **Python** might be a good choice to start experimenting with Machine Learning I decided to learn its basic syntax first. As a result a [ğŸ Playground and Cheatsheet for Learning Python](https://github.com/trekhleb/learn-python) project came out. This was just to practice Python and at the same time to have a cheatsheet of basic syntax once I need it (for things like `dict_via_comprehension = {x: x**2 for x in (2, 4, 6)}` etc.).

2. ğŸ—“ After learning a bit of Python I wanted to dig into the basic **math** behind Machine Learning. So after passing an awesome [Machine Learning course by Andrew Ng](https://www.coursera.org/learn/machine-learning) on Coursera the [ğŸ¤– Homemade Machine Learning](https://github.com/trekhleb/homemade-machine-learning) project came out. This time it was about creating a cheatsheet for basic machine learning math algorithms like linear regression, logistic regression, k-means, multilayer perceptron etc.

3. ğŸ—“ The next attempt to play around with basic Machine Learning math was [ğŸ¤– NanoNeuron](https://github.com/trekhleb/nano-neuron). It was about 7 simple JavaScript functions that supposed to give you a feeling of how machines can actually "learn".

4. ğŸ—“ After finishing yet another awesome [Deep Learning Specialization by Andrew Ng](https://www.coursera.org/specializations/deep-learning) on Coursera I decided to practice a bit more with **multilayer perceptrons**, **convolutional** and **recurrent neural networks** (CNNs and RNNs). This time instead of implementing everything from scratch I decided to start using some machine learning framework. I ended up using [TensorFlow 2](https://www.tensorflow.org/) with [Keras](https://www.tensorflow.org/guide/keras/overview). I also didn't want to focus too much on math (letting the framework do it for me) and instead I wanted to come up with something more practical, applicable and something I could try to play with right in my browser. As a result new [ğŸ¤– Interactive Machine Learning Experiments](https://github.com/trekhleb/machine-learning-experiments) came out that I want to describe a bit more here.

## Tech-stack

### Models training

- ğŸ‹ğŸ»â€ I used [Keras](https://www.tensorflow.org/guide/keras/overview) inside [TensorFlow 2](https://www.tensorflow.org/) for modelling and training. Since I had zero experience with machine learning frameworks, I needed to start with something. One of the selling points in favor of TensorFlow was that it has both Python and [JavaScript flavor](https://www.tensorflow.org/js) of the library with similar API. So eventually I used Python version for training and JavaScript version for demos. 

- ğŸ‹ğŸ»â€ I trained TensorFlow models on Python inside [Jupyter](https://jupyter.org/) notebooks locally and sometimes used [Colab](https://colab.research.google.com/) to make the training faster on GPU.

- ğŸ’» Most of the models were trained on good old MacBook's Pro CPU (2,9 GHz Dual-Core Intel Core i5).

- ğŸ”¢ Of course there is no way you could run away from [NumPy](https://numpy.org/) for matrix/tensors operations.   

### Models demo

- ğŸ‹ğŸ»â€ I used [TensorFlow.js](https://www.tensorflow.org/js) to do predictions with previously trained models.

- â™»ï¸ To convert _Keras HDF5_ models to _TensorFlow.js Layers_ format I used [TensorFlow.js converter](https://github.com/tensorflow/tfjs/tree/master/tfjs-converter). This might be inefficient to transfer the whole model (megabytes of data) to the browser instead of making predictions through HTTP requests, but again, remember that these are just experiments and not production-ready code and architecture. I wanted to avoid having a dedicated back-end service to make architecture simpler.

- ğŸ‘¨ğŸ»â€ğŸ¨ The [Demo application](http://trekhleb.github.io/machine-learning-experiments) was created on [React](https://reactjs.org/) using [create-react-app](https://github.com/facebook/create-react-app) starter with a default [Flow](https://flow.org/en/) flavour for type checking.

- ğŸ’…ğŸ» For styling, I used [Material UI](https://material-ui.com/). It was, as they say, "to kill two birds" at once and try out a new styling framework (sorry, [Bootstrap](https://getbootstrap.com/) ğŸ¤·ğŸ»â€). 

## Experiments

So, in short, you may access Demo page and Jupyter notebooks by these links:

- ğŸ¨ [**Launch ML experiments demo**](http://trekhleb.github.io/machine-learning-experiments)
- ğŸ‹ï¸ [**Check ML experiments Jupyter notebooks**](https://github.com/trekhleb/machine-learning-experiments)

### Experiments with Multilayer Perceptron (MLP)

> A [multilayer perceptron (MLP)](https://en.wikipedia.org/wiki/Multilayer_perceptron) is a class of feedforward artificial neural network (ANN). Multilayer perceptrons are sometimes referred to as "vanilla" neural networks (composed of multiple layers of perceptrons), especially when they have a single hidden layer.

#### Handwritten Digits Recognition

You draw a digit, and the model tries to recognize it.

- ğŸ¨ [Demo](https://trekhleb.github.io/machine-learning-experiments/#/experiments/DigitsRecognitionMLP)
- ğŸ‹ï¸ [Training in Jupyter](https://nbviewer.jupyter.org/v2/gh/trekhleb/machine-learning-experiments/blob/master/experiments/digits_recognition_mlp/digits_recognition_mlp.ipynb)
- ï¸ğŸ‹ï¸  [Training in Colab](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/digits_recognition_mlp/digits_recognition_mlp.ipynb)

![Handwritten Digits Recognition](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/story/03-digits-recognition.gif)

#### Handwritten Sketch Recognition

You draw a sketch, and the model tries to recognize it.

- ğŸ¨ [Demo](https://trekhleb.github.io/machine-learning-experiments/#/experiments/SketchRecognitionMLP)
- ğŸ‹ï¸ [Training in Jupyter](https://nbviewer.jupyter.org/v2/gh/trekhleb/machine-learning-experiments/blob/master/experiments/sketch_recognition_mlp/sketch_recognition_mlp.ipynb)
- ï¸ğŸ‹ï¸  [Training in Colab](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/sketch_recognition_mlp/sketch_recognition_mlp.ipynb)

![Handwritten Sketch Recognition](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/story/04-sketch-recognition.gif)

### Experiments with Convolutional Neural Networks (CNN)

> A [convolutional neural network (CNN, or ConvNet)](https://en.wikipedia.org/wiki/Convolutional_neural_network) is a class of deep neural networks, most commonly applied to analyzing visual imagery (photos, videos). They are used for detecting and classifying objects on photos and videos, style transfer, face recognition, pose estimation etc.

#### Handwritten Digits Recognition (CNN)

You draw a digit, and the model tries to recognize it. This experiment is similar to the one from MLP section, but it uses CNN under the hood.

- ğŸ¨ [Demo](https://trekhleb.github.io/machine-learning-experiments/#/experiments/DigitsRecognitionCNN)
- ğŸ‹ï¸ [Training in Jupyter](https://nbviewer.jupyter.org/v2/gh/trekhleb/machine-learning-experiments/blob/master/experiments/digits_recognition_cnn/digits_recognition_cnn.ipynb)
- ï¸ğŸ‹ï¸  [Training in Colab](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/digits_recognition_cnn/digits_recognition_cnn.ipynb)

![Handwritten Digits Recognition (CNN)](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/story/03-digits-recognition.gif)

#### Handwritten Sketch Recognition (CNN)

You draw a sketch, and the model tries to recognize it. This experiment is similar to the one from MLP section, but it uses CNN under the hood.

- ğŸ¨ [Demo](https://trekhleb.github.io/machine-learning-experiments/#/experiments/SketchRecognitionCNN)
- ğŸ‹ï¸ [Training in Jupyter](https://nbviewer.jupyter.org/v2/gh/trekhleb/machine-learning-experiments/blob/master/experiments/sketch_recognition_cnn/sketch_recognition_cnn.ipynb)
- ï¸ğŸ‹ï¸  [Training in Colab](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/sketch_recognition_cnn/sketch_recognition_cnn.ipynb)

![Handwritten Sketch Recognition (CNN)](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/story/04-sketch-recognition.gif)

#### Rock Paper Scissors (CNN)

You play a Rock-Paper-Scissors game with the model. This experiment uses CNN that is trained from scratch.

- ğŸ¨ [Demo](https://trekhleb.github.io/machine-learning-experiments/#/experiments/RockPaperScissorsCNN)
- ğŸ‹ï¸ [Training in Jupyter](https://nbviewer.jupyter.org/v2/gh/trekhleb/machine-learning-experiments/blob/master/experiments/rock_paper_scissors_cnn/rock_paper_scissors_cnn.ipynb)
- ï¸ğŸ‹ï¸  [Training in Colab](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/rock_paper_scissors_cnn/rock_paper_scissors_cnn.ipynb)

![Rock Paper Scissors (CNN)](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/story/05-rock-paper-scissors.gif)

#### Rock Paper Scissors (MobilenetV2)

You play a Rock-Paper-Scissors game with the model. This model uses transfer learning and is based on [MobilenetV2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2).

- ğŸ¨ [Demo](https://trekhleb.github.io/machine-learning-experiments/#/experiments/RockPaperScissorsMobilenetV2)
- ğŸ‹ï¸ [Training in Jupyter](https://nbviewer.jupyter.org/v2/gh/trekhleb/machine-learning-experiments/blob/master/experiments/rock_paper_scissors_mobilenet_v2/rock_paper_scissors_mobilenet_v2.ipynb)
- ï¸ğŸ‹ï¸  [Training in Colab](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/rock_paper_scissors_mobilenet_v2/rock_paper_scissors_mobilenet_v2.ipynb)

![Rock Paper Scissors (MobilenetV2)](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/story/06-rock-paper-scissors-mobilenet.gif)

#### Objects Detection (MobileNetV2)

You show to the model your environment through your camera, and it will try to detect and recognize the objects. This model uses transfer learning and is based on [MobilenetV2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2).

- ğŸ¨ [Demo](https://trekhleb.github.io/machine-learning-experiments/#/experiments/ObjectsDetectionSSDLiteMobilenetV2)
- ğŸ‹ï¸ [Training in Jupyter](https://nbviewer.jupyter.org/v2/gh/trekhleb/machine-learning-experiments/blob/master/experiments/objects_detection_ssdlite_mobilenet_v2/objects_detection_ssdlite_mobilenet_v2.ipynb)
- ï¸ğŸ‹ï¸  [Training in Colab](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/objects_detection_ssdlite_mobilenet_v2/objects_detection_ssdlite_mobilenet_v2.ipynb)

![Objects Detection (MobileNetV2)](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/story/07-objects-detection.gif)

#### Image Classification (MobileNetV2)

You upload a picture, and the model tries to classify it depending on what it "sees" on the picture. This model uses transfer learning and is based on [MobilenetV2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2).

- ğŸ¨ [Demo](https://trekhleb.github.io/machine-learning-experiments/#/experiments/ImageClassificationMobilenetV2)
- ğŸ‹ï¸ [Training in Jupyter](https://nbviewer.jupyter.org/v2/gh/trekhleb/machine-learning-experiments/blob/master/experiments/image_classification_mobilenet_v2/image_classification_mobilenet_v2.ipynb)
- ï¸ğŸ‹ï¸  [Training in Colab](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/image_classification_mobilenet_v2/image_classification_mobilenet_v2.ipynb)

![Image Classification (MobileNetV2)](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/story/08-image-classification.gif)

### Experiments with Recurrent Neural Networks (RNN) 

> A [recurrent neural network (RNN)](https://en.wikipedia.org/wiki/Recurrent_neural_network) is a class of deep neural networks, most commonly applied to sequence-based data like speech, voice, text or music. They are used for machine translation, speech recognition, voice synthesis etc.

#### Numbers Summation

You type a summation expression (i.e. `17+38`), and the model predicts the result (i.e. `55`). The interesting part here is that the model treats the input as a _sequence_, meaning it learned that when you type a sequence `1` â†’ `17` â†’ `17+` â†’ `17+3` â†’ `17+38` it "translates" it to another sequence `55`. You may think about it as translating a Spanish `Hola` sequence to English `Hello`.

- ğŸ¨ [Demo](https://trekhleb.github.io/machine-learning-experiments/#/experiments/NumbersSummationRNN)
- ğŸ‹ï¸ [Training in Jupyter](https://nbviewer.jupyter.org/v2/gh/trekhleb/machine-learning-experiments/blob/master/experiments/numbers_summation_rnn/numbers_summation_rnn.ipynb)
- ï¸ğŸ‹ï¸  [Training in Colab](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/numbers_summation_rnn/numbers_summation_rnn.ipynb)

![Numbers Summation](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/story/09-numbers-summation.gif)

#### Shakespeare Text Generation

You start typing a poem like Shakespeare, and the model will continue it like Shakespeare. At least it will try to do so ğŸ˜€.

- ğŸ¨ [Demo](https://trekhleb.github.io/machine-learning-experiments/#/experiments/TextGenerationShakespeareRNN)
- ğŸ‹ï¸ [Training in Jupyter](https://nbviewer.jupyter.org/v2/gh/trekhleb/machine-learning-experiments/blob/master/experiments/text_generation_shakespeare_rnn/text_generation_shakespeare_rnn.ipynb)
- ï¸ğŸ‹ï¸  [Training in Colab](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/text_generation_shakespeare_rnn/text_generation_shakespeare_rnn.ipynb)

![Shakespeare Text Generation](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/story/10-shakespeare-text-generation.gif)

#### Wikipedia Text Generation

You start typing a Wiki article, and the model tries to continue it.

- ğŸ¨ [Demo](https://trekhleb.github.io/machine-learning-experiments/#/experiments/TextGenerationWikipediaRNN)
- ğŸ‹ï¸ [Training in Jupyter](https://nbviewer.jupyter.org/v2/gh/trekhleb/machine-learning-experiments/blob/master/experiments/text_generation_wikipedia_rnn/text_generation_wikipedia_rnn.ipynb)
- ï¸ğŸ‹ï¸  [Training in Colab](https://colab.research.google.com/github/trekhleb/machine-learning-experiments/blob/master/experiments/text_generation_wikipedia_rnn/text_generation_wikipedia_rnn.ipynb)

![Wikipedia Text Generation](https://raw.githubusercontent.com/trekhleb/machine-learning-experiments/master/assets/images/story/11-wikipedia-text-generation.gif)

## Future plans

As I've mentioned above the main purpose of [the repository](https://github.com/trekhleb/machine-learning-experiments) is to be more like a playground for learning rather than for production-ready models. Therefore, the main plan is to **continue learning and experimenting** with deep-learning challenges and approaches. The next interesting challenges to play with might be:

- Emotions detection
- Style transfer
- Language translation
- Generating images (i.e. handwritten numbers)
- etc.

Another interesting opportunity would be to **tune existing models to make them more performant**. I believe it might give a better understanding of how to overcome overfitting and underfitting and what to do with the model if it just stuck on `60%` accuracy level for both training and validation sets and doesn't want to improve anymore ğŸ¤”.

Anyways, I hope you might find some useful insights for models training from [the repository](https://github.com/trekhleb/machine-learning-experiments) or at least to have some fun playing around with the demos!

Happy learning! ğŸ¤–
